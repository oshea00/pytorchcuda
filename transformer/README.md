# Transformer Trained from Scratch
Source for this code comes from the Kaggle workbook
[Transformer From Scratch With PyTorch](https://www.kaggle.com/code/lusfernandotorres/transformer-from-scratch-with-pytorch?scriptVersionId=157547654)

The dataset used to train the model can be found On HuggingFace Datasets [Helsinki-NLP opus-books](https://huggingface.co/datasets/Helsinki-NLP/opus_books)
Inspired by the original paper [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)

And, lastly, the YouTube video [Coding a Transformer from scratch on PyTorch](https://www.youtube.com/watch?v=ISNdQcPhsts)


